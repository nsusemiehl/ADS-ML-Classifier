{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20af2c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ads\n",
    "import requests\n",
    "import PyPDF2\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import urllib3\n",
    "import time\n",
    "from requests.adapters import TimeoutSauce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee67c9",
   "metadata": {},
   "source": [
    "https://ui.adsabs.harvard.edu/help/api/api-docs.html#get-/resolver/-bibcode-/-link_type-\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c318626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADS_DEV_KEY = \"FEbkvybqpxpJQdeF5E8btv7KvfFM4Eh5ezHV7Z8S\"\n",
    "ads.config.token = \"FEbkvybqpxpJQdeF5E8btv7KvfFM4Eh5ezHV7Z8S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8f9978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bibcodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997HIP...C......0E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003A&amp;A...401..781F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003AJ....126.1090C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004ApJS..154...10F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004ApJS..154...25R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>2022A&amp;A...663A.145H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>2022ApJS..259...62I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>2022AJ....164..198M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>2021AJ....161....5W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>2022arXiv221001027A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2780 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Bibcodes\n",
       "0     1997HIP...C......0E\n",
       "1     2003A&A...401..781F\n",
       "2     2003AJ....126.1090C\n",
       "3     2004ApJS..154...10F\n",
       "4     2004ApJS..154...25R\n",
       "...                   ...\n",
       "2775  2022A&A...663A.145H\n",
       "2776  2022ApJS..259...62I\n",
       "2777  2022AJ....164..198M\n",
       "2778  2021AJ....161....5W\n",
       "2779  2022arXiv221001027A\n",
       "\n",
       "[2780 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in database bibcodes\n",
    "\n",
    "db_bibcodes = pd.read_csv(\".//data//db_bibcodes.csv\")\n",
    "db_bibcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e43281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bibcodes from the lit tracker\n",
    "\n",
    "# auth = ('nsuse', '')\n",
    "\n",
    "# def isNaN(string):\n",
    "#     return string != string\n",
    "\n",
    "\n",
    "# r = requests.get('https://confluence.ipac.caltech.edu/rest/api/content/349470824',\n",
    "#     params={'expand': 'body.storage,version'},\n",
    "#     auth=auth)\n",
    "\n",
    "# json_conf = r.json()\n",
    "\n",
    "# text = r.json()['body']['storage']['value']\n",
    "\n",
    "# all_dfs = pd.read_html(text)\n",
    "\n",
    "# lit_tracker_bibcodes = []\n",
    "# for i in range(len(all_dfs)):\n",
    "#     if i == 3 or i == 4 or i==8:\n",
    "#         bibs = list(all_dfs[i].iloc[:,0])\n",
    "#     elif i == 16:\n",
    "#         continue\n",
    "#     else:\n",
    "#         bibs = list(all_dfs[i].iloc[:,1])\n",
    "\n",
    "#     lit_tracker_bibcodes.extend([str(j) for j in bibs if not isNaN(j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc0d0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lit tracker bibcodes to 'lit_tracker_bibcodes.txt'\n",
    "\n",
    "# with open('lit_tracker_bibcodes.txt', 'w') as f:\n",
    "#     for line in lit_tracker_bibcodes:\n",
    "#         f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a666ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1465"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in lit tracker bibcodes\n",
    "\n",
    "lit_tracker_bibcodes = []\n",
    "with open('.//data//lit_tracker_bibcodes.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        lit_tracker_bibcodes.append(line.strip())\n",
    "len(lit_tracker_bibcodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fae01695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# request function for getting PDFs\n",
    "\n",
    "def download_source_pdf(bibcode, source, folder): # source is \"pub\" or \"eprint\"\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {ADS_DEV_KEY}',\n",
    "        'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36',\n",
    "    }\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=10)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    response = session.get(f'https://ui.adsabs.harvard.edu/link_gateway/{bibcode}/{source}_pdf', headers=headers)\n",
    "    with open(f'.//data//{folder}/{bibcode}.pdf', 'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88994b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# request function for getting other things\n",
    "\n",
    "def get_url(url):\n",
    "    headers = {\n",
    "    'Authorization': f'Bearer {ADS_DEV_KEY}',\n",
    "    'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36',\n",
    "    }\n",
    "    session = requests.Session()\n",
    "    \n",
    "    retry = Retry(connect=3, backoff_factor=10)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    response = session.get(url, headers=headers, timeout=5)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()[\"response\"][\"docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb87702",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_url(f'https://api.adsabs.harvard.edu/v1/search/query?q=bibcode:{\"2022AJ....164..138S\"}&fl=keyword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959db613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# downloads PDFs from database bibcodes\n",
    "\n",
    "# directory = \".//data//EA papers//\"\n",
    "# files = os.listdir(directory)\n",
    "# downloaded_bibs = [f[:-4] for f in files]\n",
    "\n",
    "# for bibcode in db_bibcodes[\"Bibcodes\"]:\n",
    "#     if bibcode in downloaded_bibs:\n",
    "#         print(bibcode, \"existing\")\n",
    "#         file_name = bibcode + \".pdf\"\n",
    "#         file_size = os.path.getsize(directory+file_name)\n",
    "        \n",
    "#         if file_size < 80000:\n",
    "#             try:\n",
    "#                 download_source_pdf(bibcode, \"eprint\")\n",
    "#             except:\n",
    "#                 continue\n",
    "        \n",
    "#     else:\n",
    "#         print(bibcode, \"new\")\n",
    "#         download_pub_pdf(bibcode, \"pub\")\n",
    "        \n",
    "#         file_name = bibcode + \".pdf\"\n",
    "#         file_size = os.path.getsize(directory+file_name)\n",
    "#         if file_size < 80000:\n",
    "#             try:\n",
    "#                 download_source_pdf(bibcode, \"eprint\")\n",
    "#             except:\n",
    "#                 continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download PDFs from lit tracker bibcodes\n",
    "\n",
    "# directory = \".//data//EA papers//\"\n",
    "# files = os.listdir(directory)\n",
    "# downloaded_bibs = [f[:-4] for f in files]\n",
    "\n",
    "# for bibcode in lit_tracker_bibcodes:\n",
    "#     if bibcode in downloaded_bibs:\n",
    "#         file_name = bibcode + \".pdf\"\n",
    "#         file_size = os.path.getsize(directory+file_name)\n",
    "        \n",
    "#         if file_size < 80000:\n",
    "#             try:\n",
    "#                 download_EA_source_pdf(bibcode, \"eprint\")\n",
    "#             except:\n",
    "#                 continue\n",
    "        \n",
    "#     else:\n",
    "#         download_EA_source_pdf(bibcode, \"pub\")\n",
    "        \n",
    "#         file_name = bibcode + \".pdf\"\n",
    "#         file_size = os.path.getsize(directory+file_name)\n",
    "#         if file_size < 80000:\n",
    "#             try:\n",
    "#                 download_EA_source_pdf(bibcode, \"eprint\")\n",
    "#             except:\n",
    "#                 continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get negative bibcodes; check if \"exoplanet\" is not in keywords first\n",
    "# negative bibcodes are saved to 'nonexoplanet_negatives.txt'\n",
    "\n",
    "negative_bibcodes = []\n",
    "\n",
    "# need to iterate through small year chunks manually\n",
    "year = 2016\n",
    "while year <= 2022:\n",
    "    next_year = year + 2\n",
    "    print(year, next_year)\n",
    "    \n",
    "    result = get_url(f'https://api.adsabs.harvard.edu/v1/search/query?&q=database:astronomy&fq=property:refereed&fq=year:[{year} TO {next_year}]&rows=2000&fl=bibcode')\n",
    "    bibcodes = [i[\"bibcode\"] for i in result if i[\"bibcode\"] not in db_bibcodes and i[\"bibcode\"] not in negative_bibcodes and i[\"bibcode\"] not in lit_tracker_bibcodes] # also not in nonexoplanet_negatives2.txt\n",
    "\n",
    "    nonexoplanet_negative_bibcodes = []\n",
    "    for bib in bibcodes:\n",
    "        response = get_url(f'https://api.adsabs.harvard.edu/v1/search/query?q=bibcode:{bib}&fl=keyword')\n",
    "        print(response)\n",
    "        \n",
    "        if len(response) > 0:\n",
    "            exoplanet = False\n",
    "\n",
    "            if \"keyword\" in response[0].keys():\n",
    "                keyword = response[0][\"keyword\"]\n",
    "                keyword_search = [re.search(\"planet\", i.lower()) for i in keyword]\n",
    "                if any(keyword_search):\n",
    "                    exoplanet = True\n",
    "                    continue\n",
    "\n",
    "                if not exoplanet:\n",
    "                    print(bib)\n",
    "                    nonexoplanet_negative_bibcodes.append(bib)\n",
    "                    with open('.//data//nonexoplanet_negatives.txt', 'a') as f:\n",
    "                        f.write(f\"{bib}\\n\")\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    negative_bibcodes.extend(nonexoplanet_negative_bibcodes)\n",
    "    year += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd7aefd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9794\n",
      "9202\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './/data//checked_exoplanet_negatives.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14636/4113371523.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mchecked_exoplanet_negative_bibcodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.//data//checked_exoplanet_negatives.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mchecked_exoplanet_negative_bibcodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './/data//checked_exoplanet_negatives.txt'"
     ]
    }
   ],
   "source": [
    "# read in negative bibcodes\n",
    "\n",
    "negative_bibcodes = []\n",
    "with open('.//data//nonexoplanet_negatives.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        negative_bibcodes.append(line.strip())\n",
    "        \n",
    "negative_bibcodes = np.unique(negative_bibcodes) # there are some duplicates\n",
    "print(len(negative_bibcodes))\n",
    "\n",
    "checked_nonexoplanet_negative_bibcodes = []\n",
    "with open('.//data//checked_nonexoplanet_negatives.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        checked_nonexoplanet_negative_bibcodes.append(line.strip())\n",
    "        \n",
    "print(len(checked_nonexoplanet_negative_bibcodes))\n",
    "\n",
    "checked_exoplanet_negative_bibcodes = []\n",
    "with open('.//data//checked_exoplanet_negatives.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        checked_exoplanet_negative_bibcodes.append(line.strip())\n",
    "        \n",
    "print(len(checked_exoplanet_negative_bibcodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6703e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking keywords\n",
    "\n",
    "random.shuffle(negative_bibcodes)\n",
    "\n",
    "for bib in negative_bibcodes:\n",
    "    \n",
    "    if bib in checked_nonexoplanet_negative_bibcodes or bib in checked_exoplanet_negative_bibcodes:\n",
    "        continue\n",
    "        \n",
    "    response = get_url(f'https://api.adsabs.harvard.edu/v1/search/query?q=bibcode:{bib}&fl=keyword')\n",
    "    print(bib, response)\n",
    "    \n",
    "    if len(response) > 0:\n",
    "        exoplanet = False\n",
    "\n",
    "        if \"keyword\" in response[0].keys():\n",
    "            keyword = response[0][\"keyword\"]\n",
    "            keyword_search = [re.search(\"planet\", i.lower()) for i in keyword]\n",
    "            if any(keyword_search):\n",
    "                exoplanet = True\n",
    "                with open('checked_exoplanet_negatives.txt', 'a') as f:\n",
    "                    f.write(f\"{bib}\\n\")\n",
    "                continue\n",
    "\n",
    "            if not exoplanet:\n",
    "                with open('checked_nonexoplanet_negatives.txt', 'a') as f:\n",
    "                    f.write(f\"{bib}\\n\")\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd91430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download PDFs of negative bibcodes\n",
    "\n",
    "random.shuffle(negative_bibcodes)\n",
    "\n",
    "directory = \".//data//non-EA papers//\"\n",
    "files = os.listdir(directory)\n",
    "downloaded_bibs = [f[:-4] for f in files]\n",
    "\n",
    "for bibcode in negative_bibcodes:\n",
    "    if bibcode in downloaded_bibs:\n",
    "        file_name = bibcode + \".pdf\"\n",
    "        file_size = os.path.getsize(directory+file_name)\n",
    "        \n",
    "        if file_size < 80000:\n",
    "            try:\n",
    "                download_source_pdf(bibcode, \"eprint\", \"non-EA papers\")\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    else:\n",
    "        download_source_pdf(bibcode, \"pub\", \"non-EA papers\")\n",
    "        \n",
    "        file_name = bibcode + \".pdf\"\n",
    "        file_size = os.path.getsize(directory+file_name)\n",
    "        if file_size < 80000:\n",
    "            try:\n",
    "                download_source_pdf(bibcode, \"eprint\", \"non-EA papers\")\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3fa11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7980\n",
      "7980\n"
     ]
    }
   ],
   "source": [
    "# check that there are no lit tracker or db papers in with the negatives\n",
    "\n",
    "directory = \".//data//non-EA papers//\"\n",
    "files = os.listdir(directory)\n",
    "downloaded_bibs = [f[:-4] for f in files]\n",
    "print(len(downloaded_bibs))\n",
    "\n",
    "for bib in downloaded_bibs:\n",
    "    if \"desktop\" in bib:\n",
    "        continue\n",
    "    if (bib in lit_tracker_bibcodes) or (bib in db_bibcodes) or (bib not in negative_bibcodes):\n",
    "        print(bib)\n",
    "        os.remove(directory+bib+\".pdf\") \n",
    "        \n",
    "files = os.listdir(directory)\n",
    "downloaded_bibs = [f[:-4] for f in files]\n",
    "print(len(downloaded_bibs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85267448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
